{"cells":[{"cell_type":"markdown","id":"2afc4859","metadata":{},"source":["# Task 2 Input"]},{"cell_type":"code","execution_count":40,"id":"83df4590","metadata":{},"outputs":[],"source":["from pyspark.sql import SparkSession\n","from pyspark import SparkContext\n","from pyspark import SparkConf\n","from pyspark.sql.functions import udf, col, regexp_extract, size, explode, when, sum\n","from pyspark.sql.types import ArrayType, StringType, DoubleType\n","import regex\n","import os\n","os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.12:0.14.0 pyspark-shell'"]},{"cell_type":"code","execution_count":41,"id":"4e77b295","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["spark = SparkSession.builder.getOrCreate()\n","df_small = spark.read.format('xml').options(rowTag='page').load('hdfs:/enwiki_small.xml')"]},{"cell_type":"code","execution_count":42,"id":"525b841a","metadata":{},"outputs":[],"source":["new_df_small = df_small.select(\"id\", \"title\", \"revision.text._VALUE\")\n","new_df_small = new_df_small.na.drop()"]},{"cell_type":"code","execution_count":43,"id":"50ca656b","metadata":{},"outputs":[],"source":["def find_all(line):\n","    return regex.findall(r'\\[\\[((?:[^[\\]]+|(?R))*+)\\]\\]', line)\n","\n","udf_find_all = udf(lambda x: find_all(x), ArrayType(StringType()))\n","ext_df_small = new_df_small.withColumn(\"ext_links\", udf_find_all(col('_VALUE')))\n","ext_df_small = ext_df_small.filter(size(\"ext_links\") > 0)"]},{"cell_type":"code","execution_count":44,"id":"a890765d","metadata":{},"outputs":[],"source":["def filter_second(links):\n","    ignore_colon = list(filter(lambda link: (\":\" not in link) or (link.split(\":\")[0] == \"Category\"), links))\n","    ignore_hash = list(filter(lambda link: \"#\" not in link, ignore_colon))\n","    get_first_link = list(map(lambda link: link.split(\"|\")[0].strip().lower(), ignore_hash))\n","    remove_empty_space = list(filter(lambda link: link != \"\" and link != \" \", get_first_link))\n","    return remove_empty_space\n","\n","udf_filter_second = udf(lambda row: filter_second(row), ArrayType(StringType()))\n","udf_lower_title = udf(lambda title: title.strip().lower(), StringType())\n","filtered_df_small = ext_df_small.withColumn(\"filtered\", udf_filter_second(col(\"ext_links\"))).select(\"title\", \"filtered\")\n","lower_df_small = filtered_df_small.withColumn(\"lower_title\", udf_lower_title(col(\"title\"))).select(\"lower_title\", \"filtered\")\n","\n","# out_df_small = lower_df_small.select(lower_df_small.lower_title, explode(lower_df_small.filtered))\n","# out_df_small = out_df_small.na.drop()\n","# out_df_small.write.option(\"delimiter\",\"\\t\").csv(\"/q2-small\") # type cmd $hadoop fs -ls /"]},{"cell_type":"markdown","id":"40eea209","metadata":{},"source":["# Task 3"]},{"cell_type":"code","execution_count":45,"id":"1db72510","metadata":{},"outputs":[],"source":["from pyspark.sql.types import IntegerType, StringType\n","from pyspark.sql.functions import lit, udf"]},{"cell_type":"code","execution_count":51,"id":"00af8449","metadata":{"scrolled":false},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 369:===================================================> (195 + 4) / 200]\r"]},{"name":"stdout","output_type":"stream","text":["+--------------------+-------------------+\n","|                link|               rank|\n","+--------------------+-------------------+\n","|                   !|  0.171044626835241|\n","|                 !!!|0.23687939018615603|\n","|          !karapuri!|0.15241048298312454|\n","|      !kung language|0.15145200114181587|\n","|        !kung people| 0.1847503799278357|\n","|             !wowow!|0.16967012024828182|\n","|                !x처천| 0.8496391669100382|\n","|       !x처천 language| 0.7575407455107532|\n","|                   \"|0.16710676368388205|\n","|  \"a piece of steak\"|0.26906294689522287|\n","|            \"a+0(m)\"|0.15121186558719574|\n","|    \"broadway micky\"|0.15108130326172414|\n","|  \"crocodile\" dundee| 1.4305781244030518|\n","|\"do not disturb\" ...|0.15070338314476076|\n","|\"dr. death\" steve...|0.15144716065482225|\n","| \"einstein\" anderson| 0.1530546649085847|\n","|  \"from hell\" letter|0.15097215077257337|\n","|\"hello world\" pro...|0.23132052774993134|\n","|            \"heroes\"|  42.07056617910268|\n","|     \"heroes\" (song)| 0.2731186504504217|\n","+--------------------+-------------------+\n","only showing top 20 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["def compute_length(links):\n","    return len(links)\n","udf_length = udf(lambda row: compute_length(row))\n","\n","\n","links = lower_df_small.na.drop().withColumnRenamed(\"lower_title\", \"link\")\n","ranks = links\n","ranks = ranks.withColumn(\"rank\", lit(1.0)).drop(\"filtered\")\n","\n","for _ in range(10):\n","    cont = links.join(ranks, \"link\")\n","    cont = cont.withColumn(\"num_neighbors\", udf_length(cont.filtered))\n","    cont = cont.withColumn(\"contribution\", cont.rank/cont.num_neighbors)\\\n","            .drop(\"link\", \"rank\", \"num_neighbors\")\n","    cont = cont.select(explode(cont.filtered),cont.contribution)\n","    cont = cont.withColumnRenamed(\"col\", \"link\")\n","    cont = links.join(cont,on=\"link\",how='fullouter')\n","    cont = cont.withColumn(\"cont\", when(cont.contribution.isNull(), 0.0)\\\n","                           .otherwise(cont.contribution)).drop(\"filtered\",\"contribution\")\n","    cont = cont.groupBy('link').agg(sum(\"cont\").alias(\"total\"))\n","    ranks = cont.withColumn(\"rank\", when(cont.total>0, 0.15+0.85*cont.total).otherwise(0.0))\n","    ranks = ranks.drop(\"total\")\n","    \n","ranks.cache()\n","ranks = ranks.filter(ranks.rank>0)\n","ranks.sort(\"link\",\"rank\").show()"]},{"cell_type":"code","execution_count":53,"id":"15effb66","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["out_df = ranks.sort(\"link\", \"rank\").limit(5)\n","out_df.write.option(\"delimiter\",\"\\t\").csv(\"/q8\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"nbformat":4,"nbformat_minor":5}